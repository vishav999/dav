Ques 1: Given below is a dictionary having two keys ‘Boys’ and ‘Girls’ and having two lists of heights of five Boys and five Girls respectively as values associated with these keys
Original dictionary of lists:
{'Boys': [72, 68, 70, 69, 74], 'Girls': [63, 65, 69, 62, 61]}
From the given dictionary of lists create the following list of dictionaries:
[{'Boys': 72, 'Girls': 63}, {'Boys': 68, 'Girls': 65}, {'Boys': 70, 'Girls': 69}, {'Boys': 69, 'Girls': 62}, {‘Boys’:74, ‘Girls’:61]

Code:
dict_1 = {'Boys': [72, 68, 70, 69, 74], 'Girls': [63, 65, 69, 62, 61]}
result = [{'Boys': boys_height, 'Girls': girls_height} for boys_height, girls_height in zip(dict_1['Boys'], dict_1['Girls'])]
print(result)
li = []
for i in range(len(dict_1["Boys"])):
    li.append({"Boys": dict_1["Boys"][i], "Girls": dict_1["Girls"][i]})



Ques 2: Write programs in Python using NumPy library to do the following:
Code:
import numpy as np
arr = np.arange(10).reshape(2,5)
arr

a. Compute the mean, standard deviation, and variance of a two dimensional random integer array along the second axis
Code:
print("Mean = ", np.mean(arr, axis = 1))

b. Get the indices of the sorted elements of a given array.
a. B = [56, 48, 22, 41, 78, 91, 24, 46, 8, 33]
Code:
B = [56, 48, 22, 41, 78, 91, 24, 46, 8, 33]
indices = np.argsort(B)
print(indices)
print(np.sort(B))

c. Create a 2-dimensional array of size m x n integer elements, also print the shape, type and data type of the array and then reshape it into nxm array, n and m are user inputs given at the run time.
Code:
arr = np.arange(10).reshape(2,5)
arr
arr.shape
type(arr)
arr.dtype
n = int(input("Enter no. rows = "))
m = int(input("Enter no. cols = "))
arr.reshape(n,m)

d. Test whether the elements of a given array are zero, non-zero and NaN. Record the indices of
these elements in three separate arrays.
Code:
import numpy as np
arr=np.array([[np.nan,0],[7,70],[8,np.nan]])
print(np.where(np.isnan(arr1)))
print(np.where(arr1==0))
print(np.where(arr1!=0))



Ques 3: Create a dataframe having at least 3 columns and 50 rows to store numeric data generated using a random function. Replace 10% of the values by null values whose index positions are generated using random function.
Do the following:
Code:
import numpy as np
import pandas as pd
df = pd.DataFrame(np.random.rand(150).reshape(50,3), columns = ["A", "B", "C"])
m = df.replace(np.random.randint(15), np.nan)
while():
    randindex = np.random.randint(50)
    print(randindex)
    i = i + 1
    
nan_df = np.random.random(df.shape)<0.1
df_nan = df.mask(nan_df)
df_nan

a. Identify and count missing values in a dataframe.
Code:
r1 = 50
c1 = 3
data = np.random.rand(r1, c1)
null_index = np.random.choice([True, False], size = (r1, c1), p = [0.10, 0.90])
data[null_index] = np.nan
df1 = pd.DataFrame(data)
print(df1)
df1.isnull().sum()

b. Drop the column having more than 5 null values.
Code:
df1.dropna(thresh = 5, axis = 1)

c. Identify the row label having maximum of the sum of all values in a row and drop that row.
Code:
row_with_max_sum = df.sum(axis=1).idxmax()
df1 = df1.drop(index=row_with_max_sum)
df1

d. Sort the dataframe on the basis of the first column.
Code:
df1.sort_values(by = 0)

e. Remove all duplicates from the first column.
Code:
df1.drop_duplicates([0])

f. Find the correlation between first and second column and covariance between second and third column.
Code:
df1[0].corr(df1[1])
df1[1].cov(df1[2])

g. Detect the outliers and remove the rows having outliers.
Code:
def removeOutliers(df, column_name):
    Q1 = df[column_name].quantile(0.25)
    Q3 = df[column_name].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 *IQR
    upper_bound = Q3 + 1.5 * IQR
    df_filtered = df[(df[column_name] >= lower_bound) & (df[column_name] <= upper_bound)]
    
    return df_filtered

df1_cleaned = removeOutliers(df1, 0)
df1_cleaned

h. Discretize second column and create 5 bins
Code:
bins = [0, 0.2, 0.4, 0.6, 0.8, 1.0]
df1_bins = pd.cut(df1[1], bins)
df1_bins



Ques 4: Consider two excel files having attendance of a workshop’s participants for two days. Each file has three fields ‘Name’, ‘Time of joining’, duration (in minutes) where names are unique within a file. Note that duration may take one of three values (30, 40, 50) only. Import the data into two dataframes and do the following:
Code:
import numpy as np
import pandas as pd
d1 = pd.read_excel(r"C:\Users\visha\Downloads\data1.xlsx")
d2 = pd.read_excel(r"C:\Users\visha\Downloads\data2.xlsx")
d1
d2

a. Perform merging of the two dataframes to find the names of students who had attended the workshop on both days.
Code:
common_attendees = pd.merge(d1, d2, on='Name', how='inner')
print("Names of students who attended the workshop on both days:")
print(common_attendees['Name'])

b. Find names of all students who have attended workshop on either of the days.
Code:
all_attendees = pd.merge(d1, d2, on='Name', how='outer')
print("\nNames of all students who attended the workshop on either day:")
print(all_attendees['Name'])

c. Merge two data frames row-wise and find the total number of records in the data frame.
Code:
merged_row_wise = pd.concat([d1, d2], ignore_index=True)
print("\nTotal number of records after merging row-wise:", len(merged_row_wise))

d. Merge two data frames and use two columns names and duration as multi-row indexes. Generate descriptive statistics for this multi-index.
Code:
merged_multi_index = pd.merge(d1, d2, on=['Name', 'Duration'], how='outer')
print("\nDescriptive statistics for merged data with multi-row indexes:")
print(merged_multi_index.groupby(['Name', 'Duration']).describe())



Ques5: Taking Iris data, plot the following with proper legend and axis labels: (Download IRIS data from:
https://archive.ics.uci.edu/ml/datasets/iris or import it from sklearn.datasets)
Code:
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
column_names = ["sepal length", "sepal width", "petal length", "petal width","class"]
df=pd.read_csv(r"C:\Users\visha\Downloads\iris.data", header = None, names = column_names)
df

a. Plot bar chart to show the frequency of each class label in the data.
Code:
plt.hist(df["class"], color = "green")
plt.bar(df["class"], height = 60)

b. Draw a scatter plot for Petal width vs sepal width.
Code:
x =df["petal width"]
y =df["sepal width"]
plt.scatter(x, y, color = "Orange")

c. Plot density distribution for feature petal length.
Code:
df["petal length"].plot.density()
df["petal length"]

d. Use a pair plot to show pairwise bivariate distribution in the Iris Dataset.
Code:
sns.pairplot(df)



Ques 6: Consider any sales training/ weather forecasting dataset
Code:
import numpy as np
import pandas as pd
df1= pd.read_csv(r'C:\Users\visha\Downloads\XboxOne_GameSales.csv', encoding = 'unicode_escape')
df1.head()
df1.isna().sum()

a. Compute mean of a series grouped by another series
Code:
temp=df1.groupby("Publisher")["Europe"].mean()
temp.head(50)

b. Fill an intermittent time series to replace all missing dates with values of previous non-missing date.
Code:
df1["Year"]=df1["Year"].fillna(method='ffill')
df1.isna().sum()

c. Perform appropriate year-month string to dates conversion.
Code:
dt=list()
from datetime import datetime
for i in df1["Year"]:
  dt.append(datetime.strptime(str(i),'%Y.%M'))
dt

d. Split a dataset to group by two columns and then sort the aggregated results within the groups.
Code:
df1.groupby(["Genre","Publisher"])["Europe"].mean().sort_values(ascending=False)

e. Split a given dataframe into groups with bin counts.
Code:
bins=[0,1,2,3,4,5,6,7,8,9,10]
cats=pd.cut(df1["North America"],bins)
cats



Ques7: Consider a data frame containing data about students i.e. name, gender and passing division:
Code:
import pandas as pd;
df= {"NAME":["Mudit Chauhan","Seema Chopra","Rani Gupta","Aditya Narayan","Sanjeev Sahni","Prakash Kumar","Ritu Agarwal","Akshay Goel","Meeta Kulkarni","Preeti Ahuja","Sunil Das Gupta","Sonali Sapre","Rashmi Talwar","Ashish Dubey","Kiran Sharma","Sameer Bansal"],
                 "Birth_Month":["December","January","March","October","Feburary","December","September","August","July","November","April","January","June","May","Feburary","October"],
                "Gender":["M","F","F","M","M","M","F","M","F","F","M","F","F","M","F","M"],
                "Pass_Division":["III","II","I","I","II","III","I","I","II","II","III","I","III","II","II","I"]}
df1=pd.DataFrame(df)

a. Perform one hot encoding of the last two columns of categorical data using the get_dummies() function.
Code:
df1.info()
df2= pd.get_dummies(df1,columns=["Gender","Pass_Division"])
df2
#Using transform
from sklearn.preprocessing import OneHotEncoder 
df1["Gender"]=df1["Gender"].astype("category")
df1["Pass_Division"]=df1["Pass_Division"].astype("category")
df1["new_gender"]=df1["Gender"].cat.codes
df1["new_division"]=df1["Pass_Division"].cat.codes
enc=OneHotEncoder()
df3=pd.DataFrame(enc.fit_transform(df1[["new_gender","new_division"]]).toarray())
new_df=df1.join(df3)
new_df.rename(columns={0:"Female",1:"Male",2:"First Div",3:"Second Div",4:"Third Div"},inplace=True)
new_df[["Female","Male","First Div","Second Div","Third Div"]]=new_df[["Female","Male","First Div","Second Div","Third Div"]].astype("int64")
new_df.drop(["Gender","Pass_Division","new_gender","new_division"],axis=1)

b. Sort this data frame on the “Birth Month” column (i.e. January to December). Hint: Convert Month to Categorical
Code:
months_order = ["January", "Feburary", "March", "April", "May", "June", "July", "August", "September", "October", "November", "December"]
df1["Birth_Month"]=pd.Categorical(df1["Birth_Month"], categories= months_order ,ordered=True)
df1.sort_values(by="Birth_Month")



Ques8: Consider the following data frame containing a family name, gender of the family member and her/his monthly income in each record.
Write a program in Python using Pandas to perform the following:
Code:
import pandas as pd
import numpy as np
data = {"Name" : ["Shah","Vats", "Vats", "Kumar","Vats","Kumar", "Shah", "Shah", "Kumar", "Vats"], 
        "Gender" : ["Male","Male","Female","Female","Female","Male","Male","Female","Female","Male"],
        "MonthlyIncome": [114000.00, 65000.00, 43150.00, 69500.00, 155000.00, 103000.00, 55000.00, 112400.00, 81030.00, 71900.00]}
df = pd.DataFrame(data)
df

a. Calculate and display familywise gross monthly income.
Code:
data1 = df.loc[:,["Name", "Gender", "MonthlyIncome"]]
data1

b. Calculate and display the member with the highest monthly income in a family.
Code:
data1.groupby("Name")["MonthlyIncome"].sum()
data1.groupby("Name")["MonthlyIncome"].max()

c. Calculate and display monthly income of all members with income greater than Rs. 60000.00.
Code:
data1[data1["MonthlyIncome"]>=60000.00]

d. Calculate and display the average monthly income of the female members in the Shah family.
Code:
data1.groupby(["Name", "Gender"])[["MonthlyIncome"]].mean().query("Name =='Shah' and Gender =='Female'")